
1. 파이썬
파이썬은 범용 프로그래밍 언어의 장점은 물론 매트랩과 R같은 특정 분야를 위한 스크립팅 언어의 편리함을 함께 갖췄습니다. 또한 데이터 적재, 시각화, 통계, 자연어 처리, 이미지 처리 등에 필요한 라이브러리들을 가지고 있습니다.
복잡한 GUI나 웹 서비스도 만들 수 있으며 기존 시스템과 통합하기도 좋기 때문에 저희는 파이썬을 선택했습니다.

머신러닝에 대한 라이브러리가 파이썬으로 쓰인게 많아서 저희는 우선 파이썬을 공부하기로 했습니다.
무엇으로 공부할까 찾아보다가 점프 투 파이썬는 책을 옮겨놓은 페이지를 찾았습니다.
이 페이지는 한글로 되어 있고 예시와 설명이 아주 적절하게 쓰여있습니다.
다음은 파이썬 홈페이지에 있는 설명인데요 원서로 되어있습니다.
저희는 이 두 사이트를 이용해 파이썬에 대한 기본적인 것들을 공부했습니다.


2. 머신러닝
머신러닝을 공부하기 위해서 어떤 프레임워크를 공부할까 고민하던 중
저희는 딥러닝 보다는 머신러닝을 공부하는게 목적이기 때문에 
딥러닝 특화인 TensorFlow보다는 머신러닝에 대한 알고리즘이 잘 나타나있는 Scikit-learn을 선택했습니다.
또한 scikit-learn;사이킷 런 이라는 오픈 소스는 자유롭게 사용하거나 배포할 수 있고, 
누구나 소스 코드를 보고 실제로 어떻게 동작하는지 쉽게 확인할 수 있습니다. 


3. 필수 라이브러리
scikit-learn은 파이썬 과학 라이브러리인 NumPy와 SciPy를 기반으로 만들어졌습니다.
그래프를 그리려면 matplotlib을, 데이터 처리하려면 pandas를,
대화식으로 개발하려면 IPython또는 주피터 노트북이 필요합니다.


1) 주피터 노트북
주피터 노트북은 프로그램 코드를 브라우저에서 실행해주는 대화식 환경입니다. 
이런 방식은 탐색적 데이터 분석에 아주 적합하여 많은 데이터 분석가가 주피터 노트북을 사용하고 있습니다. 

2) NumPy
파이썬으로 과학 계산을 하려면 꼭 필요한 패키지입니다.
다차원 배열을 위한 기능과 선형 대수 연산과 고수준 수학 함수와 유사 난수 생성기를 포함합니다.
scikit-learn에서 NumPy 배열은 기본 데이터 구조이기 때문에 사용할 데이터는 모두 NumPy 배열로 변환 되어야 합니다.
NumPy의 핵심 기능은 다차원(n-차원) 배열인 ndarray 클래스입니다. 
이 배열의 모든 원소는 동일한 데이터 타입이어야 합니다.

3) SciPy
과학 계산용 함수를 모아놓은 파이썬 패키지입니다.
SciPy는 고성능 선형 대수, 함수 최적화, 신호 처리, 특수한 수학 함수와 통계 분포 등을 포함한 많은 기능을 제공합니다.
그 중에서 가장 중요한 기능은 scipy.sparse입니다.
이 모듈은 scikit-learn에서 데이터를 표현하는 또 하나의 방법인 희소 행렬 기능을 제공합니다.
희소 행렬은 0을 많이 포함한 2차원 배열을 저장할 때 사용합니다.

4) matplotilib
파이썬의 대표적인 과학 계산용 그래프 라이브러리입니다. 
선 그래프, 히스토그램, 산점도 등을 지원하며 출판에 쓸 수 있을 만큼의 고품질 그래프를 그려줍니다. 
데이터와 분석 결과를 다양한 관점에서 시각화해보면 매우 중요한 통찰을 얻을 수 있습니다.
주피터 노트북에서 사용할 때는 %matplotlib notebook 이나 %matplotlib inline 명령을 사용하면 브라우저에서 바로 이미지를 볼 수 있습니다.

5) pandas
데이터 처리와 분석을 위한 파이썬 라이브러리입니다. 
R의 data.frame을 본떠서 설계한 DataFrame이라는 데이터 구조를 기반으로 만들어졌습니다.
간단하게 말하면 pandas의 DataFrame은 엑셀의 스프레드시트와 비슷한 테이블 형태라고 할 수 있습니다. 
pandas는 이 테이블을 수정하고 조작하는 다양한 기능을 제공합니다.
특히, SQL처럼 테이블에 쿼리나 조인을 수행할 수 있습니다. 
전체 배열의 원소가 동일한 타입이어야 하는 NumPy와 달리 pandas는 각 열의 타입이 달라도 됩니다. (구조체?)
SQL, 엑셀 파일, CSV 파일 같은 다양한 파일과 데이터베이스에서 데이터를 읽어 들일 수 있는 것이 
	pandas가 제공하는 또 하나의 유용한 기능입니다. 
다음 코드는 딕셔너리를 사용하여 DataFrame을 만드는 간단한 예제입니다.




4. 예제

간단한 머신러닝 애플리케이션을 예시로 들면서 핵심 개념과 용어를 소개하겠습니다.
어떤 사람이 붓꽃 하나를 발견했는데 이 붓꽃의 품종을 알고 싶다고 가정하겠습니다.
그 사람은 붓꽃의 꽃잎과 꽃받침의 폭과 길이를 센티미터 단위로 측정하였습니다.
또한 전문가가 Setosa, Versicolor, Virginica 종으로 분류한 붓꽃의 측정 데이터도 가지고 있습니다.
이 측정값을 이용해서 앞에서 채집한 붓꽃이 어떤 품종인지 구분하려고 합니다.

우리의 목표는 어떤 품종인지 구분해놓은 측정 데이터를 이용해 새로 채집한 붓꽃의 품종을 예측하는 머신러닝 모델을 만드는 것입니다.

붓꽃의 품종을 정확하게 분류한 데이터를 가지고 있으므로 이 문제는 지도 학습에 속합니다.
/* 이 경우에는 몇 가지 선택사항(붓꽃의 품종)중 하나를 선택하는 문제입니다.
     그러므로 이 예는 분류 문제에 해당합니다. */
출력될 수 있는 값(붓꽃의 종류)들을 클래스라고 합니다.
이 예시에서는 붓꽃의 종이 세가지라서 세 개의 클래스가 있다고 할 수 있습니다.

데이터 포인트는 측정된 값들 즉 측정된 붓꽃 데이터라고 할 수 있습니다.

이 예시에서는 하나의 붓꽃이 어떤 품종인지 구분하려고 하는 것이기 때문에
데이터 포인트 하나(붓꽃 하나)에 대한 기대 출력은 꽃의 품종이 됩니다.
이런 특정 데이터 포인트에 대한 출력, 즉 품종을 레이블이라고 합니다.

데이터 셋 : 컴퓨터에서 사용할 수 있도록 저장된 유사하거나 관련된 데이터(자료)들의 집합체이다.


1) 데이터 적재
우리가 사용할 데이터 셋은 머신 러닝과 통계 분야에서 오래전부터 사용해온 붓꽃 데이터셋입니다.
이 데이터는 scikit-learn의 datasets 모듈에 포함되어 있습니다.
load_iris 함수를 사용해서 데이터를 적재하겠습니다.

load_iris가 반환한 iris 객체는 키와 값으로 구성되어 있습니다.
파이썬의 딕셔너리와 유사한 Bunch 클래스의 객체입니다.

DESCR 키에는 데이터셋에 대한 간략한 설명이 들어 있습니다.
앞부분만 조금 살펴보겠습니다.

target_names의 값은 우리가 예측하려는 붓꽃 품종의 이름을 문자열 배열로 가지고 있습니다.

feature_names의 값은 각 특성을 설명하는 문자열 리스트입니다.

실제 데이터는 target과 data필드에 들어 있습니다.
data는 꽃잎의 길이와 폭, 꽃받침의 길이와 폭을 수치 값으로 가지고 있는 NumPy 배열입니다.

data 배열의 행은 개개의 꽃이 되며 열은 각 꽃에서 구한 네 개의 측정치입니다.

이 배열은 150개의 붓꽃 데이터를 가지고 있습니다.
머신러닝에서 각 아이템은 '샘플'이라고 하고, 속성은 '특성'이라고 부릅니다.
그러므로 data 배열의 크기는 샘플의 수에 특성의 수를 곱한 값이 됩니다.
이는 scikit-learn의 스타일이며 항상 데이터가 이런 구조일 거라 가정하고 있습니다.
다음은 맨 처음 다섯 샘플의 특성값입니다.

이 데이터로부터 다섯 붓꽃의 꽃잎 폭은 모두 0.2cm이고, 
첫 번째 꽃이 가장 긴 5.1cm의 꽃받침을 가졌음을 알 수 있습니다.

target 배열도 샘플 붓꽃의 품종을 담은 NumPy 배열입니다.

target은 각 원소가 붓꽃 하나에 해당하는 1차원 배열입니다.

붓꽃의 종류는 0에서 2까지의 정수로 기록되어 있습니다.

숫자의 의미는 iris['target_names'] 배열에서 확인할 수 있습니다.
0은 setosa, 1은 versicolor, 2는 viginica입니다.



2) 성과측정: 훈련 데이터와 테스트 데이터
이 데이터로 머신러닝 모델을 만들고 새로운 데이터의 품종을 예측하려 합니다.
하지만 만든 모델을 새 데이터에 적용하기 전에 이 모델이 진짜 잘 작동하는지 알아야 합니다.
다시 말해서 우리가 만든 모델의 예측을 신뢰할 수 있는지 알아야 합니다.


모델의 성능을 측정하려면 레이블을 알고 있는 (이전에 본 적 없는) 새 데이터를 모델에 적용해봐야 합니다.
이를 위해 우리가 가지고 있는 레이블된 데이터, 즉 150개의 붓꽃 데이터를 두 그룹으로 나눕니다.
그중 하나는 머신러닝 모델을 만들 때 사용하며, 훈련 데이터 혹은 훈련 세트(training set)라고 합니다.
나머지는 모델이 얼마나 잘 작동하는지 측정하는 데 사용하며, 이를 테스트 데이터, 테스트 세트(test set) 

scikit-learn은 데이터셋을 섞어서 나눠주는 train_test_split 함수를 제공합니다.
이 함수는 보통 전체 행 중 75%를 레이블 데이터와 함께 훈련 세트로 뽑습니다.
나머지 25%는 레이블 데이터와 함께 테스트 세트가 됩니다.

scikit-learn에서 데이터는 대문자 X로 표시하고 레이블은 소문자 y로 표기합니다.
이는 수학에서 함수의 입력을 x, 출력을 y로 나타내는 표준 공식 f(x) = y에서 유래된 것입니다.
하지만 데이터는 2차원 배열(행렬)이므로 대문자 X를, 
	타깃은 1차원 배열(벡터)이므로 소문자 y를 사용합니다.

아까 타깃이 0,1,2로 출력된 것 처럼 데이터 포인트가 레이블 순서대로 정렬되어 있기 때문에  train_test_split 함수로 데이터를 나누기 전에 유사 난수 생성기를 사용해 데이터셋을 무작위로 섞어야 값이 골고루 섞입니다.

/* 이 함수를 여러 번 실행해도 결과가 똑같이 나오도록 유사 난수 생성기에 넣을 난수 초깃값을
      random_state 매개변수로 전달합니다.
     이렇게 하면 이 코드는 항상 같은 결과를 출력합니다.
*/
-예시


train_test_split 함수의 반환값은 X_train, X_test, y_train, y_test이며 모두 NumPy 배열입니다.
X_train은 전체 데이터셋의 75%를, X_test는 나머지 25%를 담고 있습니다.
-예시



3) 데이터 살펴보기
머신러닝 모델을 만들기 전에 머신러닝이 없이도 풀 수 있는 문제는 아닌지, 혹은 필요한 정보가 누락되지는 않았는지 데이터를 조사해보는 것이 좋습니다.
또한 데이터를 탐색하면서 비정상적인 값이나 특이한 값들을 찾을 수도 있습니다.

산점도는 데이터에서 한 특성을 x축에 놓고 다른 하나는 y축에 놓아 각 데이터 포인트를 하나의 점으로 나타내는 그래프입니다.
꽃잎의 길이와 폭, 꽃받침의 길이와 폭 이 네가지를 두개찍 짝지어 점을 찍는 것입니다.
이렇게 모든 특성을 짝지어 만드는 산점도 행렬(scatter matrix)을 사용할 수 있습니다.

그림은 훈련 세트를 사용해 만든 4개의 특성에 대한 산점도 행렬입니다.
데이터 포인트의 색은 붓꽃의 품종에 따라 구분했습니다.
이 그래프를 그리려면 먼저 NumPy배열을 pandas의 DataFrame으로 변경해야 합니다.
pandas는 산점도 행렬을 그려주는 scatter_matrix 함수를 제공하기 때문입니다.
이 그림의 대각선에 위치한 그래프는 각 특성의 히스토그램입니다.
-그림



4) 첫 번째 머신러닝 모델: k-최근접 이웃 알고리즘
이제 실제 머신러닝 모델을 만들어보겠습니다.
scikit-learn은 다양한 분류 알고리즘을 제공하는데 
여기서는 비교적 이해하기 쉬운 k-최근접 이웃 분류기를 사용하겠습니다.
이 모델은 단순히 훈련 데이터를 저장하여 만들어집니다.
새로운 데이터 포인트에 대한 예측이 필요하면 알고리즘은 새 데이터 포인트에서 가장 가까운 훈련 데이터 포인트를 찾습니다.
그런 다음 찾은 훈련 데이터의 레이블을 새 데이터 포인트의 레이블로 지정합니다.


k-최근접 이웃 알고리즘에서 k는 가장 가까운 이웃 '하나'가 아니라 가장 가까운 'k개'의 이웃을 찾는다는 뜻입니다.
그런 다음 이 이웃들의 클래스 중 빈도가 가장 높은 클래스를 예측값으로 사용합니다.
자세한 내용은 2장에서 살펴보도록 하고, 지금은 하나의 이웃만 사용하겠습니다.

k-최근접 이웃 분류 알고리즘은 neighbors 모듈 아래 KNeighborsClassifier 클래스에 구현되어있습니다.
모델을 사용하려면 클래스로부터 객체를 만들어야 합니다.
이때 모델에 필요한 매개변수를 넣습니다.
KNeighborsClassifier에서 가장 중요한 매개변수는 이웃의 개수입니다.
우리는 1로 지정하겠습니다.
-

knn 객체는 훈련 데이터로 모델을 만들고 새로운 데이터 포인트에 대해 예측하는 알고리즘을 캡슐화한 것입니다.
또한 알고리즘이 훈련 데이터로부터 추출한 정보를 담고 있습니다.
KNeighborsClassifier의 경우는 훈련 데이터 자체를 저장하고 있습니다.

훈련 데이터셋으로부터 모델을 만들려면 knn 객체의 fit 메서드를 사용합니다.
이 메서드는 훈련 데이터인 NumPy 배열 X_train과 훈련 데이터의 레이블을 담고 있는 NumPy 배열 y_train을 매개변수로 받습니다.
-

fit 메서드는 knn 객체 자체를 반환합니다.(그리고 knn객체 자체를 변경시킵니다.)
그래서 knn객체가 문자열 형태로 출력됩니다.
이 출력에서 모델을 생성할 때 사용한 매개변수를 볼 수 있습니다.
거의 모든 매개변수가 기본 값이고 n_neighbors=1은 우리가 지정한 값입니다.



5) 예측하기
이제 이 모델을 사용해서 정확한 레이블을 모르는 새 데이터에 대해 예측을 만들 수 있습니다.
야생에서 꽃받침의 길이가 5cm, 폭이 2.9cm이고 꽃잎의 길이가 1cm, 폭이 0.2cm인 붓꽃을 보았다고 가정합니다.
그럼 이 붓꽃의 품종은 무엇일까요?
먼저 이 측정값을 NumPy 배열, 즉 샘플의 수(1)에 특성의 수(4)를 곱한 크기의 NumPy 배열로 만들어보겠습니다.
-

붓꽃 하나의 측정값은 2차원  NumPy 배열에 행으로 들어갑니다.
scikit-learn은 항상 데이터가 2차원 배열일 것으로 예상합니다.
예측에는 knn 객체의 predict 메서드를 사용합니다.
-

우리가 만든 모델이 새로운 붓꽃을 setosa 품종을 의미하는 클래스 0으로 예측했습니다.
그런데 어떻게 이 모델의 결과를 신뢰할 수 있을까요?
이 샘플의 정확한 품종을 모른다는 사실이 모델을 구축하는 데 있어서 중요한 의미를 가집니다.


6) 모델 평가하기
앞서 만든 테스트 세트를 사용할 때가 왔습니다.
이 데이터는 모델을 만들 때 사용하지 않았고 테스트 세트에 있는 각 붓꽃의 품종을 정확히 알고 있습니다.

따라서 테스트 데이터에 있는 붓꽃의 품종을 예측하고 실제 레이블(품종)과 비교할 수 있습니다.
얼마나 많은 붓꽃 품종이 정확히 맞았는지 정확도를 계산하여 모델의 성능을 평가합니다.
-

또 knn 객체의 score 메서드로도 테스트 세트의 정확도를 계산할 수 있습니다.
-

이 모델의 테스트 세트에 대한 정확도는 약 0.97 입니다.
이 말은 테스트 세트에 포함된 붓꽃 중 97%의 품종을 정확히 맞혔다는 뜻입니다.
이 결과 이 모델은 새로운 붓꽃에 대한 정확도가 97%일 것이라 기대할 수 있습니다.
정확도가 높으므로 일반인들도 이 애플리케이션을 충분히 신뢰하고 사용할만합니다.


이로써 어떤 품종인지 구분해놓은 측정 데이터를 이용해 새로 채집한 붓꽃의 품종을 예측하는 
머신러닝 모델을 만들게 되었습니다.
감사합니다.